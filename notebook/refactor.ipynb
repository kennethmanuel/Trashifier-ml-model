{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33cc6b0-267b-4b51-88d6-d9bacdc57919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Hide TensorFlow Warning due to using GPU\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519fb79d-942b-4b26-bae3-de583cab6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../dataset/Extended WaDaBa\"\n",
    "data_dir = pathlib.Path(data_dir) #pathlib.Path respect different semantics appropriate for different operating systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3f00eb-172c-4749-b81e-b8ee3a6ed8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variable\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baed4433-fa72-4ebb-a343-8dd28108e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlled Variable\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "num_channels = 3\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "fine_tune_epoch = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "580ff42e-98e8-4a8f-835a-1887925ab266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      seed=123,\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size=batch_size)\n",
    "    \n",
    "    class_names = ds.class_names\n",
    "    return ds, class_names\n",
    "    \n",
    "def preprocess_ds(ds):\n",
    "    def preprocess_image(images, labels):\n",
    "        preprocessed_images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "        return preprocessed_images, labels\n",
    "    \n",
    "    preprocessed_ds = ds.map(preprocess_image)\n",
    "    return preprocessed_ds\n",
    "\n",
    "def get_dataset_partitions(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=15515):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    ds_size = tf.data.experimental.cardinality(ds).numpy()\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=123)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def configure_performance(train_ds, val_ds, test_ds):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def create_model(num_class, learning_rate, dropout_rate):\n",
    "    # Load the pre-trained MobileNetV2 model without the top classification layer\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    \n",
    "    # Freeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Custom classification layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "    \n",
    "    # Create the transfer learning model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(model, train_ds, val_ds, epochs):\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    return history\n",
    "\n",
    "def plot_loss(history, save_path):\n",
    "    plt.plot(range(epochs), history.history['loss'], label='Training Loss')\n",
    "    plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_accuracy(history, save_path):\n",
    "    plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def get_predictions_labels(ds, model):\n",
    "    predictions = np.array([])\n",
    "    labels =  np.array([])\n",
    "    for x, y in test_ds:\n",
    "      predictions = np.concatenate([predictions, np.argmax(model.predict(x), axis = -1)])\n",
    "      labels = np.concatenate([labels, y.numpy()])\n",
    "      \n",
    "    return predictions, labels\n",
    "\n",
    "def generate_classification_report(labels, predictions, save_path):\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(save_path, index=False)\n",
    "\n",
    "def plot_confusion_matrix(labels, predictions, class_names, save_path):\n",
    "    confusion_matrix = tf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xticks(np.arange(len(class_names)))\n",
    "    ax.set_yticks(np.arange(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=90)  # Rotate x-axis labels vertically\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    # Add the value annotations to the plot\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            text = ax.text(j, i, confusion_matrix[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "    # Display the colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # Automatically adjust subplot parameters\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "def fine_tune(model, num_layers_to_freeze):\n",
    "    # Freeze layers except for the last `num_layers_to_freeze` layers\n",
    "    num_layers = len(model.layers)\n",
    "    for layer in model.layers[:num_layers - num_layers_to_freeze]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[num_layers - num_layers_to_freeze:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate/10), \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fine_tune_fit(model, train_ds, val_ds, epochs, history):\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, initial_epoch=history.epoch[-1])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a618e8-df6b-4d7a-a72a-79c305bb86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4545 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "ds, class_names = load_dataset()\n",
    "ds = preprocess_ds(ds)\n",
    "train_ds, val_ds, test_ds = get_dataset_partitions(ds, train_split=0.8, val_split=0.1, test_split=0.1)\n",
    "train_ds, val_ds, test_ds = configure_performance(train_ds, val_ds, test_ds)\n",
    "model = create_model(len(class_names), learning_rate, dropout_rate)\n",
    "history = train(model, train_ds, val_ds, epochs)\n",
    "plot_loss(history, 'loss_plot.png')\n",
    "plot_accuracy(history, 'accuracy_plot.png')\n",
    "predictions, labels = get_predictions_labels(test_ds, model)\n",
    "generate_classification_report(labels, predictions, 'classification_report.csv')\n",
    "plot_confusion_matrix(labels, predictions, class_names, 'confusion_matrix.png')\n",
    "model.save('model.h5')\n",
    "print(\"Number of layers in the base model: \", len(model.layers))\n",
    "# last 30 layer from mobilenet, 6 is the custom classification layer\n",
    "fine_tuned_model = fine_tune(model, 36)\n",
    "fine_tuned_history = fine_tune_fit(fine_tuned_model, train_ds, val_ds, fine_tune_epoch, history)\n",
    "plot_loss(fine_tuned_history, 'fine_tune_loss_plot.png')\n",
    "plot_accuracy(fine_tuned_history, 'fine_tune_accuracy.png')\n",
    "predictions, labels = get_predictions_labels(test_ds, fine_tuned_model)\n",
    "generate_classification_report(labels, predictions, 'classification_report_fine_tune.csv')\n",
    "plot_confusion_matrix(labels, predictions, class_names, 'confusion_matrix_fine_tune.png')\n",
    "model.save('fine_tune_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
